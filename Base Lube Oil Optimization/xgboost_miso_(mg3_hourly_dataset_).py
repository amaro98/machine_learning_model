# -*- coding: utf-8 -*-
"""XGBoost MISO (MG3 Hourly Dataset )

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1InUqwPuEJI-cKzvbuFTgPLplwBNesocG

#**XGBoost MISO for MG3 (Process Variable as Input)**

##Mount Google Drive & Install latest modules
"""

from google.colab import drive
drive.mount('/content/drive')

#!pip install optuna
!pip install xgboost
#uninstall 0.90, install 1.4.2

"""##Importing Libraries"""

'''
from google.colab import files
uploaded = files.upload()
'''

import pandas as pd
import numpy as np

from google.colab import data_table
from numpy import absolute
from pandas import read_csv
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedKFold
from sklearn.multioutput import MultiOutputRegressor
from xgboost import XGBClassifier
from numpy import absolute
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
import xgboost as xgb
import matplotlib.pyplot as plt
import numpy as np
import plotly.express

plotly.__version__

"""## Importing Datasets

here, the data is imported into dataframes - `df`
"""

# Commented out IPython magic to ensure Python compatibility.

#Use workseet :alldata_allrows"

# %reload_ext google.colab.data_table
df = pd.read_excel("/content/drive/MyDrive/00 MACHINE LEARNING/MG3/Dataset - Dataset_MG3_hourly_ID_Preprocessed_Auto_Manual_Input.xlsx")

'''
-  Process Variables (Input) at Column 3 to Column 33
-  Dependant Variables (Output) at last column
'''

X_PV = df.iloc[:,2:34]
y = df.iloc[:,53]


#Observe top 5 dataframe

#X_PV.head()
y.head()


#Count how many elements in Dependent Variable column (y)

unique, counts = np.unique(y, return_counts=True)
dict(zip(unique, counts))

"""## Train Test Split"""

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

# Total Data                                               : 46194
# Reserved for Train_Test (80%)                            : 36956
# Reserved for Model Testing after development (20%)       : 9239

# Input                                                    : X_PV or X_ALL
# Output                                                   : y_he




#          |    ROW    |   COLUMN    |

Xdev = X_PV.iloc[0:36956,:].values
ydev = y.iloc[0:36956].values      

Xdep = X_PV.iloc[36956:,:]
ydep = y.iloc[36956:] 

X_train, X_test, y_train, y_test = train_test_split(Xdev,ydev, test_size=0.2, random_state = None)

#Count how many elements in Dependent Variable column (y_train/y_test/ydep)

unique, counts = np.unique(ydep, return_counts=True)
dict(zip(unique, counts))

for i in range (32):
  print(i+1,X_PV.columns[i])

X_new = X_PV.iloc[255:256,:].values
X_new.shape

X_t = np.transpose(X_new, axes = None)
X_t.shape

X_new.shape

"""##Label Encoder"""

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
import sys
import numpy
numpy.set_printoptions(threshold=sys.maxsize)

#One Hot Encoding Training Data
label_encoder = LabelEncoder()
label_encoder = label_encoder.fit(y_train)
label_encoded_y = label_encoder.transform(y_train)

#One Hot Encoding Test Data
label_encoder = LabelEncoder()
label_encoder = label_encoder.fit(y_test)
label_encoded_y = label_encoder.transform(y_test)

#One Hot Encoding Unseen Data
label_encoder = LabelEncoder()
label_encoder = label_encoder.fit(ydep)
label_encoded_y = label_encoder.transform(ydep)

#Observe Encoded output


ydep

"""##Developing Model"""

from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV

regressor = XGBRegressor()

params = {
      'n_estimators' : [500],
      'max_depth': [3],
      'learning_rate': [0.01,0.1,0.300000012,0.5,0.9], #eta
      #'reg_lambda': [1],
      'colsample_bylevel'  : [0.25],
      'colsample_bynode'   : [0],
      'colsample_bytree'   : [1], #
      #'gamma'              : [0], #
   #'max_delta_step'     : [0],
    
   #'min_child_weight'   : [1],
    #'reg_alpha'          : [0],
   #'scale_pos_weight'   : [1],
   #'subsample'          : [1],
  # 'n_jobs'             : [2]
}

grid_regressor = GridSearchCV(estimator = regressor,
                        param_grid = params,
                        cv = 5, 
                        verbose = 1,
                        n_jobs = -1)
grid_regressor.fit(X_train,y_train)


print("Best Estimator: \n{}\n".format(grid_regressor.best_estimator_))
print("Best Parameters: \n{}\n".format(grid_regressor.best_params_))
print("Best Test Score: \n{}\n".format(grid_regressor.best_score_))
print("All Test Scores: \n{}\n".format(grid_regressor.cv_results_['mean_test_score']))
 
cv_result = pd.DataFrame(grid_regressor.cv_results_)

print("Best Estimator: \n{}\n".format(grid_regressor.best_estimator_))
print("Best Parameters: \n{}\n".format(grid_regressor.best_params_))
print("Best Test Score: \n{}\n".format(grid_regressor.best_score_))
print("All Test Scores: \n{}\n".format(grid_regressor.cv_results_['mean_test_score']))
 
cv_result = pd.DataFrame(grid_regressor.cv_results_)

"""## Training XGBoost on Training Set

To train:

`machine_learning_model.fit(input_training_Data, output_training_data)`

To test:

`output_prediction = machine_learning_model.predict(input_test_data)`
"""

classifier = XGBClassifier()
classifier.fit(X_train, y_train)

"""## Evaluate Train Set"""

from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.metrics import plot_confusion_matrix

fig, ax = plt.subplots(figsize=(10, 10))
cm= plot_confusion_matrix(classifier,
                      X_train,
                      y_train,
                      cmap=plt.cm.Blues,
                      display_labels=["C-1","C-2","C-3","T-12","T-21","T23","T-31"],
                    values_format= '.0f',
                    ax = ax)

cm.ax_.set_title('Confusion Matrix for Training Data')
plt.show()

'''
[TRAIN DATA COUNT]

 'C-1': 15885,
 'C-2': 8546,
 'C-3': 5074,
 'T-12': 34,
 'T-21': 6,
 'T-23': 12,
 'T-31': 7}
'''

"""## Running Evaluate Test Set"""

'''
[TEST DATA COUNT]
'C-1': 3958, 
'C-2': 2161, 
'C-3': 1252, 
'T-12': 15, 
'T-21': 2, 
'T-23': 4
'''



from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.metrics import plot_confusion_matrix

y_pred = classifier.predict(X_test)

fig, ax = plt.subplots(figsize=(10, 10))
cm= plot_confusion_matrix(classifier,
                      X_test,
                      y_test,
                      cmap=plt.cm.Blues,
                      display_labels=["C-1","C-2","C-3","T-12","T-21","T23","T-31"],
                    values_format= '.0f',
                    ax = ax)

cm.ax_.set_title('Confusion Matrix for Test Data')
plt.show()

print("Prediction Accuracy: ",accuracy_score(y_test, y_pred)*100,"%")

"""##Testing on Unseen Data

Uncomment if you wish to plot Test Data vs. Predicted Data
"""

y_deploy = classifier.predict(Xdep)
y_deploy

fig, ax = plt.subplots(figsize=(10, 10))
cm= plot_confusion_matrix(classifier,
                      Xdep,
                      ydep,
                      cmap=plt.cm.Blues,
                      display_labels=["C-1","C-2","C-3","T-12","T-21","T23","T-31"],
                    values_format= '.0f',
                    ax = ax)

cm.ax_.set_title('Confusion Matrix for Reserved Data')
plt.show()

print("Prediction Accuracy: ", accuracy_score(ydep, y_deploy)*100,"%")

'''
[UNSEEN DATA COUNT]
'C-1': 4566, 
'C-2': 3077, 
'C-3': 1591, 
'T-31': 4, 
'T-32': 1
'''

"""##SAVING MODELS"""

from xgboost import Booster as bst
classifier.save_model('/content/drive/MyDrive/00 MACHINE LEARNING/MG3/xgb_MG3Hourly.model')

#X_new = X_PV.iloc[250,2:34]
X_new = X_PV.iloc[255:256,:].values

bst = classifier
config = bst.save_config()
print(config)


X_PV.shape
X_new.shape

y[255:256]

"""##LOAD MODELS"""

#y_deploy = classifier.predict(Xdep)

#Booster.load_model()
model_load = xgb.XGBClassifier()
model_load.load_model('/content/drive/MyDrive/00 MACHINE LEARNING/MG3/xgb_MG3Hourly.model')


model_load.predict(X_new)